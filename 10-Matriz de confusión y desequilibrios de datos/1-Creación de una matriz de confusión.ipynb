{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Build a confusion matrix\n",
        "\n",
        "\n",
        "In this exercise we go into more detail on measuring the performance of classification models, using the concepts of *imbalanced datasets*, *accuracy* and *confusion matrices*.\n",
        "\n",
        "\n",
        "## Data visualization\n",
        "\n",
        "Our new dataset represents different classes of objects found in snow.\n",
        "\n",
        "Let's start this exercise by loading in and having a look at our data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/snow_objects.csv\n",
        "\n",
        "#Import the data from the .csv file\n",
        "dataset = pandas.read_csv('snow_objects.csv', delimiter=\"\\t\")\n",
        "\n",
        "#Let's have a look at the data\n",
        "dataset"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "--2023-03-31 01:50:11--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 21511 (21K) [text/plain]\nSaving to: ‘graphing.py’\n\ngraphing.py         100%[===================>]  21.01K  --.-KB/s    in 0s      \n\n2023-03-31 01:50:11 (113 MB/s) - ‘graphing.py’ saved [21511/21511]\n\n--2023-03-31 01:50:13--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/snow_objects.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 143797 (140K) [text/plain]\nSaving to: ‘snow_objects.csv’\n\nsnow_objects.csv    100%[===================>] 140.43K  --.-KB/s    in 0.02s   \n\n2023-03-31 01:50:13 (8.76 MB/s) - ‘snow_objects.csv’ saved [143797/143797]\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "           size  roughness  color    motion   label\n0     50.959361   1.318226  green  0.054290    tree\n1     60.008521   0.554291  brown  0.000000    tree\n2     20.530772   1.097752  white  1.380464    tree\n3     28.092138   0.966482   grey  0.650528    tree\n4     48.344211   0.799093   grey  0.000000    tree\n...         ...        ...    ...       ...     ...\n2195   1.918175   1.182234  white  0.000000  animal\n2196   1.000694   1.332152  black  4.041097  animal\n2197   2.331485   0.734561  brown  0.961486  animal\n2198   1.786560   0.707935  black  0.000000  animal\n2199   1.518813   1.447957  brown  0.000000  animal\n\n[2200 rows x 5 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>size</th>\n      <th>roughness</th>\n      <th>color</th>\n      <th>motion</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.959361</td>\n      <td>1.318226</td>\n      <td>green</td>\n      <td>0.054290</td>\n      <td>tree</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60.008521</td>\n      <td>0.554291</td>\n      <td>brown</td>\n      <td>0.000000</td>\n      <td>tree</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.530772</td>\n      <td>1.097752</td>\n      <td>white</td>\n      <td>1.380464</td>\n      <td>tree</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28.092138</td>\n      <td>0.966482</td>\n      <td>grey</td>\n      <td>0.650528</td>\n      <td>tree</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48.344211</td>\n      <td>0.799093</td>\n      <td>grey</td>\n      <td>0.000000</td>\n      <td>tree</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2195</th>\n      <td>1.918175</td>\n      <td>1.182234</td>\n      <td>white</td>\n      <td>0.000000</td>\n      <td>animal</td>\n    </tr>\n    <tr>\n      <th>2196</th>\n      <td>1.000694</td>\n      <td>1.332152</td>\n      <td>black</td>\n      <td>4.041097</td>\n      <td>animal</td>\n    </tr>\n    <tr>\n      <th>2197</th>\n      <td>2.331485</td>\n      <td>0.734561</td>\n      <td>brown</td>\n      <td>0.961486</td>\n      <td>animal</td>\n    </tr>\n    <tr>\n      <th>2198</th>\n      <td>1.786560</td>\n      <td>0.707935</td>\n      <td>black</td>\n      <td>0.000000</td>\n      <td>animal</td>\n    </tr>\n    <tr>\n      <th>2199</th>\n      <td>1.518813</td>\n      <td>1.447957</td>\n      <td>brown</td>\n      <td>0.000000</td>\n      <td>animal</td>\n    </tr>\n  </tbody>\n</table>\n<p>2200 rows × 5 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "We can see that the dataset has both continuous (`size`, `roughness`, `motion`) and categorical data (`color` and `label`).\n",
        "Let's do some quick data exploration and see what different label classes we have and their respective counts:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import graphing # custom graphing code. See our GitHub repo for details\n",
        "\n",
        "# Plot a histogram with counts for each label\n",
        "graphing.multiple_histogram(dataset, label_x=\"label\", label_group=\"label\", title=\"Label distribution\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/py38_default/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'dask.array' has no attribute 'lib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphing\u001b[39;00m \u001b[38;5;66;03m# custom graphing code. See our GitHub repo for details\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Plot a histogram with counts for each label\u001b[39;00m\n\u001b[1;32m      4\u001b[0m graphing\u001b[38;5;241m.\u001b[39mmultiple_histogram(dataset, label_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, label_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/learn/graphing.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfromnumeric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m repeat, shape\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgraph_objects\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/plotly/express/__init__.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124;03m\"\"\"\\\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mPlotly express requires pandas to be installed.\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_imshow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imshow\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chart_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     scatter,\n\u001b[1;32m     18\u001b[0m     scatter_3d,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     density_mapbox,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     set_mapbox_access_token,\n\u001b[1;32m     57\u001b[0m     defaults,\n\u001b[1;32m     58\u001b[0m     get_trendline_results,\n\u001b[1;32m     59\u001b[0m     NO_COLOR,\n\u001b[1;32m     60\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/plotly/express/_imshow.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image_array_to_data_uri\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     xarray_imported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/xarray/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing, tutorial\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     load_dataarray,\n\u001b[1;32m      4\u001b[0m     load_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     save_mfdataset,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrasterio_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_rasterio\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/xarray/testing.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m duck_array_ops, formatting, utils\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataArray\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/xarray/core/duck_array_ops.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m take, tensordot, transpose, unravel_index  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m where \u001b[38;5;28;01mas\u001b[39;00m _where\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dask_array_compat, dask_array_ops, dtypes, npcompat, nputils\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nanfirst, nanlast\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpycompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy_array_type, dask_array_type, is_duck_dask_array\n",
            "File \u001b[0;32m/anaconda/envs/py38_default/lib/python3.8/site-packages/xarray/core/dask_array_compat.py:60\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m padded\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m da \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     sliding_window_view \u001b[38;5;241m=\u001b[39m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241m.\u001b[39mstride_tricks\u001b[38;5;241m.\u001b[39msliding_window_view\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     sliding_window_view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'dask.array' has no attribute 'lib'"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram above makes it very easy to understand both the labels we have in the dataset and their distribution.\n",
        "\n",
        "One important information to notice is that this is an *imbalanced dataset*: classes are not represented in the same proportion (we have 4 times more rocks and trees than animals, for example).\n",
        "\n",
        "This is relevant as imbalanced sets are very common \"in the wild\", and in the future we will learn how to address that to build better models.\n",
        "\n",
        "We can do the same analisys for the `color` feature:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram with counts for each label\n",
        "graphing.multiple_histogram(dataset, label_x=\"color\", label_group=\"color\", title=\"Color distribution\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can notice that:\n",
        "\n",
        "- We have `8` different color categories.\n",
        "- The `color` feature is also heavily imbalanced.\n",
        "- Out plotting algorithm is not smart enough to assign the correct colors to their respective names.\n",
        "\n",
        "Let's see what we can find about the other features:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "graphing.box_and_whisker(dataset, label_y=\"size\", title='Boxplot of \"size\" feature')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we can see that the majority of our samples are relatively small, with sizes ranging from `0` to `70`, but we have a few much bigger outliers.\n",
        "\n",
        "Let's take a look at the `roughness` feature:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "graphing.box_and_whisker(dataset, label_y=\"roughness\", title='Boxplot of \"roughness\" feature')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's not a lot of variation here: values for `roughness` range from `0` to a little over `2`, with most samples having values close to the mean.\n",
        "\n",
        "Finally, let's plot the `motion` feature:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "graphing.box_and_whisker(dataset, label_y=\"motion\", title='Boxplot of \"motion\" feature')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most objects seem to be either static or moving very slowly. There is a smaller number of objects moving faster, with a couple of outliers over `10`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the data above one could assume that the smaller and faster objects are likely hikers and animals, whereas the bigger, more static elements are trees and rocks.\n",
        "\n",
        "## Building a classification model\n",
        "\n",
        "Let's build and train a classification model using a random forest, to predict the class of an object based on the features in our dataset:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset in an 70/30 train/test ratio. \n",
        "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train our model, using the `train` dataset we've just created:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = RandomForestClassifier(n_estimators=1, random_state=1, verbose=False)\n",
        "\n",
        "# Define which features are to be used (leave color out for now)\n",
        "features = [\"size\", \"roughness\", \"motion\"]\n",
        "\n",
        "# Train the model\n",
        "model.fit(train[features], train.label)\n",
        "\n",
        "print(\"Model trained!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessing our model\n",
        "\n",
        "We can now use our newly trained model to make predictions using the *test* set.\n",
        "\n",
        "By comparing the values predicted to the actual labels (also called *true* values), we can measure the model's performance using different *metrics*.\n",
        "\n",
        "*Accuracy*, for example, is the simply number of correctly predicted labels out of all predictions performed:\n",
        "\n",
        "```sh\n",
        "    Accuracy = Correct Predictions / Total Predictions\n",
        "```\n",
        "\n",
        "Let's see how this can be done in code:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a function that measures a models accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate the model's accuracy on the TEST set\n",
        "actual = test.label\n",
        "predictions = model.predict(test[features])\n",
        "\n",
        "# Return accuracy as a fraction\n",
        "acc = accuracy_score(actual, predictions)\n",
        "\n",
        "# Return accuracy as a number of correct predictions\n",
        "acc_norm = accuracy_score(actual, predictions, normalize=False)\n",
        "\n",
        "print(f\"The random forest model's accuracy on the test set is {acc:.4f}.\")\n",
        "print(f\"It correctly predicted {acc_norm} labels in {len(test.label)} predictions.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model __seems__ to be doing quite well!\n",
        "\n",
        "That intuition, however, can be misleading:\n",
        "\n",
        "- Accuracy does not take into account the __wrong__ predictions made by the model\n",
        "\n",
        "- It's also not very good at painting a clear picture in *class-imbalanced datasets*, like ours, where the number of possible classes is not evenly distributed (recall that we have 800 trees, 800 rocks, but only 200 animals)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a confusion matrix\n",
        "\n",
        "A *confusion matrix* is a table where we compare the actual labels to what the model predicted. It gives us a more detailed understanding of how the model is doing and where it's getting things right or missing.\n",
        "\n",
        "This is one of the ways we can do that in code:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn has a very convenient utility to build confusion matrices\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Build and print our confusion matrix, using the actual values and predictions \n",
        "# from the test set, calculated in previous cells\n",
        "cm = confusion_matrix(actual, predictions, normalize=None)\n",
        "\n",
        "print(\"Confusion matrix for the test set:\")\n",
        "print(cm)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the matrix above can be useful in calculations, it's not very helpful or intuitive.\n",
        "\n",
        "Let's add a plot with labels and colors to turn that data into actual insights:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# We use plotly to create plots and charts\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Create the list of unique labels in the test set, to use in our plot\n",
        "# I.e., ['animal', 'hiker', 'rock', 'tree']\n",
        "x = y = sorted(list(test[\"label\"].unique()))\n",
        "\n",
        "# Plot the matrix above as a heatmap with annotations (values) in its cells\n",
        "fig = ff.create_annotated_heatmap(cm, x, y)\n",
        "\n",
        "# Set titles and ordering\n",
        "fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n",
        "                    yaxis = dict(categoryorder = \"category descending\"))\n",
        "\n",
        "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                        x=0.5,\n",
        "                        y=-0.15,\n",
        "                        showarrow=False,\n",
        "                        text=\"Predicted label\",\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                        x=-0.15,\n",
        "                        y=0.5,\n",
        "                        showarrow=False,\n",
        "                        text=\"Actual label\",\n",
        "                        textangle=-90,\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "# We need margins so the titles fit\n",
        "fig.update_layout(margin=dict(t=80, r=20, l=100, b=50))\n",
        "fig['data'][0]['showscale'] = True\n",
        "fig.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the plot has the __Actual labels__ on the `y-axis` and __Predicted labels__ on the `x-axis`, as defined by the `confusion_matrix` function call.\n",
        "\n",
        "We can see that the model is generally accurate, but only because we have so many rocks and trees in our set and because it does well on those classes.\n",
        "\n",
        "When it comes to hikers and animals the model gets confused (it shows a high number of FPs and FNs), but because these classes are less represented in the dataset the *accuracy score* remains high.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "In this exercise we talked about the following concepts:\n",
        "\n",
        "- *Imbalanced datasets*, where features or classes can be represented by a disproportionate number of samples.\n",
        "- *Accuracy* as a metric to assess model performance, and its shortcomings.\n",
        "- How to generate, plot and interpret *confusion matrices*, to get a better understanding of how a classification model is performing."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "conda-env-py38_default-py"
    },
    "kernelspec": {
      "name": "conda-env-py38_default-py",
      "language": "python",
      "display_name": "py38_default"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}